{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "%reload_ext watermark\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from IPython.display import display\n",
    "import sklearn as sk\n",
    "import sklearn.neural_network as sknn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "In this section we load both datasets we use, COVID-19 dataset and countries population dataset , clean the data and add some new columns.  \n",
    "\n",
    "The datasets we use are:\n",
    "\n",
    "* https://www.kaggle.com/imdevskp/corona-virus-report for the COVID-19 dataset\n",
    "\n",
    "* https://www.kaggle.com/tanuprabhu/population-by-country-2020 for population information per country\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID-19 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "\n",
    "full_table = pd.read_csv('datasets/covid_19_clean_complete.csv', \n",
    "                          na_values=['NaN'],\n",
    "                          parse_dates=['Date'])\n",
    "\n",
    "# Adding Active cases column\n",
    "full_table['Active'] = (full_table['Confirmed'] - full_table['Deaths'] - full_table['Recovered']).apply(lambda x: x if x >= 0 else 0)\n",
    "\n",
    "# filling missing values\n",
    "full_table[['Province/State']] = full_table[['Province/State']].fillna('')\n",
    "full_table[['Confirmed','Deaths','Recovered','Active']] = full_table[['Confirmed','Deaths','Recovered','Active']].fillna(0)\n",
    "\n",
    "full_table.sample(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_table = pd.read_csv('datasets/population_by_country_2020.csv',\n",
    "                        na_values=['N.A.'])\n",
    "\n",
    "\n",
    "# Selecting only the Country and Population columns\n",
    "pop_table = pop_table.iloc[:,[0,1,4,9]]\n",
    "\n",
    "\n",
    "\n",
    "# Renaming columns\n",
    "pop_table.columns = ['Country/Region', 'Population', 'Population Density (P/Km²)','Urban Population %']\n",
    "\n",
    "# Most of the entries with urban population as NaN in the population dataset that we are going to use have 100% as of 2020\n",
    "pop_table[['Urban Population %']] = pop_table[['Urban Population %']].fillna('100 %')\n",
    "pop_table['Urban Population %'] = pop_table['Urban Population %'].map(lambda x: int(x.split(' ')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_table.info()\n",
    "pop_table.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing ship data\n",
    "\n",
    "The dataset also includes data from the various ships that had COVID19 outbreaks. Since we only need the information per country we removed it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ship rows\n",
    "ship_rows = full_table['Province/State'].str.contains('Grand Princess') | full_table['Province/State'].str.contains('Diamond Princess') | full_table['Country/Region'].str.contains('Diamond Princess') | full_table['Country/Region'].str.contains('MS Zaandam')\n",
    "\n",
    "# ship\n",
    "ship = full_table[ship_rows]\n",
    "\n",
    "# dropping ship rows \n",
    "full_table = full_table[~(ship_rows)]\n",
    "\n",
    "ship.sample(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing country names\n",
    "\n",
    "\n",
    "### Fixing mismatched names between datasets\n",
    "\n",
    "Here we manually set the names so that the join between datasets works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_name_only = {\n",
    "    'Sao Tome & Principe': 'Sao Tome and Principe',\n",
    "    \"Côte d'Ivoire\": \"Cote d'Ivoire\",\n",
    "    \"United States\": \"US\",\n",
    "    \"Czech Republic (Czechia)\": 'Czechia',\n",
    "    'Myanmar': 'Burma',\n",
    "    'Taiwan': 'Taiwan*',\n",
    "    'Saint Kitts & Nevis': 'Saint Kitts and Nevis',\n",
    "    'Macao' : 'Macau'\n",
    "}\n",
    "\n",
    "for original,new in fix_name_only.items():\n",
    "    full_table.loc[full_table['Country/Region'] == new, 'Country/Region'] = original\n",
    "    full_table.loc[full_table['Province/State'] == new, 'Province/State'] = original\n",
    "\n",
    "missing_countries = set(full_table['Country/Region']).difference(set(pop_table['Country/Region']))\n",
    "\n",
    "# # print(sorted(pop_table['Country/Region'].unique()))\n",
    "# if len(missing_countries) != 0:\n",
    "#     print(missing_countries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Country/Region with Province/State\n",
    "\n",
    "The population dataset has entries for autonomous regions, for example Greenland. Here we rewrite the Country/Region column with the Province/State name so we can easily join the population dataset. For example, Greenland exists in the population dataset so what we do is replace Denmark (the Country column of Greenland) with Greenland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "province_set = set(full_table['Province/State']).intersection(set(pop_table['Country/Region']))\n",
    "\n",
    "no_data = set(['Saint Vincent and the Grenadines','Kosovo','Congo','West Bank and Gaza'])\n",
    "\n",
    "for province in province_set:\n",
    "    if province in no_data:\n",
    "        continue\n",
    "    full_table.loc[ full_table['Province/State'] == province,'Country/Region'] = province \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "full_table.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping data\n",
    "\n",
    "Here we are grouping data by Date and Country so we can add population and cases per million afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_grouped = full_table.groupby(['Country/Region','Lat','Long','Date'])['Confirmed','Deaths','Recovered','Active'].sum().reset_index()\n",
    "full_grouped_nolat = full_table.groupby(['Country/Region','Date'])['Confirmed','Deaths','Recovered','Active'].sum().reset_index()\n",
    "\n",
    "full_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding population\n",
    "In this section, we merge both datasets by Country/Region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_grouped = pd.merge(full_grouped,pop_table,on=['Country/Region'])\n",
    "full_grouped_nolat = pd.merge(full_grouped_nolat,pop_table,on=['Country/Region'])\n",
    "\n",
    "full_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating new cases per day\n",
    "\n",
    "To calculate the number of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with latitude and longitude\n",
    "temp = full_grouped.groupby(['Country/Region', 'Date'])['Confirmed', 'Deaths', 'Recovered']\n",
    "temp = temp.sum().diff().reset_index()\n",
    "\n",
    "mask = temp['Country/Region'] != temp['Country/Region'].shift(1)\n",
    "\n",
    "temp.loc[mask, 'Confirmed'] = np.nan\n",
    "temp.loc[mask, 'Deaths'] = np.nan\n",
    "temp.loc[mask, 'Recovered'] = np.nan\n",
    "\n",
    "\n",
    "temp.columns = ['Country/Region', 'Date','New cases', 'New deaths', 'New recovered']\n",
    "\n",
    "\n",
    "full_grouped = pd.merge(full_grouped,temp, on=['Country/Region', 'Date'])\n",
    "\n",
    "full_grouped = full_grouped.fillna(0)\n",
    "\n",
    "full_grouped[['New cases','New deaths','New recovered']] = full_grouped[['New cases','New deaths','New recovered']].astype('int64')\n",
    "\n",
    "#############################################################################################################################\n",
    "# # Dataset with no lat and long\n",
    "\n",
    "temp = full_grouped_nolat.groupby(['Country/Region', 'Date' ])['Confirmed', 'Deaths', 'Recovered']\n",
    "temp = temp.sum().diff().reset_index()\n",
    "\n",
    "mask = temp['Country/Region'] != temp['Country/Region'].shift(1)\n",
    "\n",
    "temp.loc[mask, 'Confirmed'] = np.nan\n",
    "temp.loc[mask, 'Deaths'] = np.nan\n",
    "temp.loc[mask, 'Recovered'] = np.nan\n",
    "\n",
    "temp.columns = ['Country/Region', 'Date', 'New cases', 'New deaths', 'New recovered']\n",
    "\n",
    "full_grouped_nolat = pd.merge(full_grouped_nolat,temp, on=['Country/Region', 'Date'])\n",
    "\n",
    "full_grouped_nolat = full_grouped_nolat.fillna(0)\n",
    "\n",
    "full_grouped_nolat[['New cases','New deaths','New recovered']] = full_grouped_nolat[['New cases','New deaths','New recovered']].astype('int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_data = full_grouped.groupby(['Date'])['Confirmed','Deaths','Recovered','Active','Population'].sum().reset_index()\n",
    "world_data.loc[world_data['Date'] == world_data['Date'].max()]\n",
    "world_data.head()\n",
    "world_pop_total = world_data['Population'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check information on types and null values\n",
    "full_grouped.info()\n",
    "full_grouped.loc[full_grouped['Urban Population %'].isnull()]['Country/Region'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_grouped.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Cases per Million of People\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_permillion(df):\n",
    "    df['Confirmed per million'] = round((df['Confirmed'] / df['Population']) * 1000000)\n",
    "    df['Deaths per million']    = round((df['Deaths'] / df['Population']) * 1000000)\n",
    "    df['Recovered per million'] = round((df['Recovered'] / df['Population']) * 1000000)\n",
    "    df['Active per million']    = round((df['Active'] / df['Population']) * 1000000)\n",
    "    return df\n",
    "\n",
    "def calc_permillion_world():\n",
    "    world_data['Confirmed per million'] = round((world_data['Confirmed'] / world_data['Population']) * 1000000)\n",
    "    world_data['Deaths per million']    = round((world_data['Deaths'] / world_data['Population']) * 1000000)\n",
    "    world_data['Recovered per million'] = round((world_data['Recovered'] / world_data['Population']) * 1000000)\n",
    "    world_data['Active per million']    = round((world_data['Active'] / world_data['Population']) * 1000000)\n",
    "\n",
    "\n",
    "\n",
    "per_million = calc_permillion(full_grouped)\n",
    "per_million_nolat = calc_permillion(full_grouped_nolat)\n",
    "\n",
    "per_million.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Truncation\n",
    "\n",
    "Since the COVID-19 dataset only has data from  22nd of January of 2020 onwards, we will define Date from here moving foward as days since the 22nd of January of 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_million['Date'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daysSinceJan(d):\n",
    "    return d.toordinal() - datetime(2020,1,20).toordinal()\n",
    "\n",
    "def revertdaysSince(d):\n",
    "    return datetime(2020,1,20) + timedelta(days=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_million_nolat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_million['Days Since Jan'] = per_million['Date'].map(daysSinceJan)\n",
    "\n",
    "per_million_nolat['Days Since Jan'] = per_million['Date'].map(daysSinceJan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_million =  per_million.sort_values(['Date','Country/Region'],ascending=[True, True])\n",
    "per_million.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_million_nolat.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding population percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_million['Pop %'] = per_million['Population'].apply(lambda x: x/world_pop_total * 100)\n",
    "per_million_nolat['Pop %'] = per_million_nolat['Population'].apply(lambda x: x/world_pop_total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_million_nolat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeChinaData(df):\n",
    "    df = df[full_grouped['Country/Region'] != 'China']\n",
    "\n",
    "removeChinaData(full_grouped)\n",
    "removeChinaData(full_grouped_nolat)\n",
    "removeChinaData(per_million_nolat)\n",
    "removeChinaData(per_million)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_million.loc[per_million['Country/Region'] == 'Portugal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_million_nolat.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and outputs\n",
    "\n",
    "This function will return a pair of inputs and outputs given the country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_train_data(df_full,country=None,out=['Confirmed per million',\t'Deaths per million',\t'Recovered per million']):\n",
    "    df = df_full\n",
    "    input  = ['Date','Population Density (P/Km²)','Urban Population %', 'Pop %']\n",
    "    if country is not None:\n",
    "        df = df_full.loc[ df_full['Country/Region'] == country]\n",
    "        input = ['Date']\n",
    "    return df[input], df[out]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_by_country_train(\n",
    "    country,\n",
    "    input=['Days Since Jan','Population Density (P/Km²)','Urban Population %','Pop %'],\n",
    "    out= ['Confirmed per million','Deaths per million','Recovered per million'],\n",
    "    hidden_layer_sizes=(100,100,100,60,60,60)\n",
    "):\n",
    "    df = per_million_nolat.loc[ per_million_nolat['Country/Region'] == country]\n",
    "    X = df[input].values\n",
    "    Y = df[out].values\n",
    "    nn = sknn.MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.00001,\n",
    "        batch_size='auto',\n",
    "        max_iter=1000,\n",
    "        n_iter_no_change=100)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.30,shuffle=True)\n",
    "    nn.fit(X_train,y_train) # Train the model\n",
    "    y_pred = nn.predict(X_test)\n",
    "\n",
    "    nnr2 = nn.score(X_test,y_test) # Calculate R² for the model\n",
    "    nnmae = mean_absolute_error(y_test,y_pred) # Mean Absolute Error\n",
    "    nnmse = mean_squared_error(y_test,y_pred)\n",
    "\n",
    "    print(\"R2:\",nnr2)\n",
    "    print(\"MAE:\",nnmae)\n",
    "    print(\"MSE:\",nnmse)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graph(world_viz,things = ['Confirmed','Deaths','Recovered'],label='C/D/R',x = 'Date',title='Title',limit_x=None):\n",
    "    sb.set()\n",
    "\n",
    "    dd = world_viz.melt([x],var_name=label, value_name='Cases',value_vars=things)\n",
    "\n",
    "\n",
    "    chart = sb.relplot(x=x,y='Cases',hue=label,data=dd,kind='line')\n",
    "\n",
    "    chart.set(title=title)\n",
    "    chart.fig.autofmt_xdate()\n",
    "    if limit_x is not None:\n",
    "        plt.axvline(limit_x,0,1,linewidth=4, color='r')\n",
    "\n",
    "    plt.show()#%%\n",
    "\n",
    "def world_train_data(df_full,country=None,out=['Confirmed per million',\t'Deaths per million',\t'Recovered per million']):\n",
    "    df = df_full\n",
    "    input  = ['Date','Population Density (P/Km²)','Urban Population %', 'Pop %']\n",
    "    if country is not None:\n",
    "        df = df_full.loc[ df_full['Country/Region'] == country]\n",
    "        input = ['Date']\n",
    "    return df[input], df[out]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def nn_by_country_train(\n",
    "    country,\n",
    "    input=['Days Since Jan','Population Density (P/Km²)','Urban Population %','Pop %'],\n",
    "    out= ['Confirmed per million','Deaths per million','Recovered per million'],\n",
    "    hidden_layer_sizes=(100,100,100,60,60,60)\n",
    "):\n",
    "    df = per_million_nolat.loc[ per_million_nolat['Country/Region'] == country]\n",
    "    X = df[input].values\n",
    "    Y = df[out].values\n",
    "    nn = sknn.MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.00001,\n",
    "        batch_size='auto',\n",
    "        max_iter=1000,\n",
    "        n_iter_no_change=100)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.30,shuffle=True)\n",
    "    nn.fit(X_train,y_train) # Train the model\n",
    "    y_pred = nn.predict(X_test)\n",
    "\n",
    "    nnr2 = nn.score(X_test,y_test) # Calculate R² for the model\n",
    "    nnmae = mean_absolute_error(y_test,y_pred) # Mean Absolute Error\n",
    "    nnmse = mean_squared_error(y_test,y_pred)\n",
    "\n",
    "    print(\"R2:\",nnr2)\n",
    "    print(\"MAE:\",nnmae)\n",
    "    print(\"MSE:\",nnmse)\n",
    "\n",
    "    return nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_graph(world_viz,things = ['Confirmed','Deaths','Recovered'],label='C/D/R',x = 'Date',title='Title',limit_x=None):\n",
    "    sb.set()\n",
    "\n",
    "    dd = world_viz.melt([x],var_name=label, value_name='Cases',value_vars=things)\n",
    "\n",
    "\n",
    "    chart = sb.relplot(x=x,y='Cases',hue=label,data=dd,kind='line')\n",
    "\n",
    "    chart.set(title=title)\n",
    "    chart.fig.autofmt_xdate()\n",
    "    if limit_x is not None:\n",
    "        plt.axvline(limit_x,0,1,linewidth=1, color='r',linestyle='--')\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getPredInp(country):\n",
    "    return [per_million.loc[per_million['Country/Region'] == country]['Population Density (P/Km²)'].max(),\n",
    "    per_million.loc[per_million['Country/Region'] == country]['Urban Population %'].max(),\n",
    "    per_million.loc[full_grouped['Country/Region'] == country]['Pop %'].max()]\n",
    "\n",
    "# per_million.loc[per_million['Country/Region'] == 'Portugal'].groupby(['Lat','Long']).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_predict(model,country,minprev=0,offset=10,maxprev=daysSinceJan(datetime.now().date() - timedelta(days=1))):\n",
    "\n",
    "    country_pop = per_million_nolat.loc[per_million_nolat['Country/Region'] == country]['Population'].max()\n",
    "    ip = []\n",
    "\n",
    "    for dat in range(minprev,maxprev+offset+1): # Predict from 0 to 155 days from January 1st 2020\n",
    "        ip.append([dat, *getPredInp(country)]) # Hard Coded Pop Density, Urban Pop %, Latitude and Longitude\n",
    "\n",
    "    out = nn.predict(ip)\n",
    "\n",
    "    nl = []\n",
    "\n",
    "    for i,o in zip(ip,out):\n",
    "        nl.append([*i,*o])\n",
    "\n",
    "    futurepredict = pd.DataFrame(nl,columns=['Date','Population Density (P/Km²)','Urban Population %',\"Pop %\",'Confirmed','Deaths','Recovered'])\n",
    "\n",
    "    futurepredict['Confirmed'] = futurepredict['Confirmed'].map(lambda x: round((x/1000000) * country_pop))\n",
    "    futurepredict['Recovered'] = futurepredict['Recovered'].map(lambda x: round((x/1000000) * country_pop))\n",
    "    futurepredict['Deaths'] = futurepredict['Deaths'].map(lambda x: round((x/1000000) * country_pop) )\n",
    "\n",
    "    futurepredict['Date'] = futurepredict['Date'].map(revertdaysSince) \n",
    "    predict = futurepredict.loc[(futurepredict['Date'] >= revertdaysSince(maxprev - 30)) & (futurepredict['Date'] <= revertdaysSince(maxprev + offset))]\n",
    "\n",
    "\n",
    "    print_graph(per_million_nolat.loc[per_million_nolat['Country/Region'] == country],['Confirmed','Deaths','Recovered'], title='Real Data')\n",
    "    print_graph(futurepredict,['Confirmed','Deaths','Recovered'],x='Date', title=\"Future prediction\",limit_x=revertdaysSince(maxprev))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "country = 'Mexico'\n",
    "nn = nn_by_country_train(country)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_predict(nn,country,offset=500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38264bitb107e19725bf425aa9d9b5580be5bc24",
   "language": "python",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}